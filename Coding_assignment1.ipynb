{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = os.listdir('./train/pos')\n",
    "train_neg = os.listdir('./train/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(address):\n",
    "    #Read all files given an address\n",
    "    #Returns: list of strings\n",
    "    my_files = os.listdir(address)\n",
    "    return [open(\"{}/{}\".format(address,i),'r', encoding='utf-8').read() for i in my_files]\n",
    "\n",
    "def shuffle_arr(arr, seed=314):\n",
    "    #Shuffles a list\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(arr)\n",
    "\n",
    "def clean_and_split(text):\n",
    "    #Takes a string, removes white spaces, makes it lowercase and splits given space\n",
    "    #Input: string\n",
    "    #Returns: list of strings\n",
    "    return text.strip().lower().split()\n",
    "\n",
    "def vocabulary_builder(collection, size=2000):\n",
    "    #Takes a list of strings and creates a simple counter and vocabulary\n",
    "    #Input: list of strings\n",
    "    #Returns: dict of strings {word:count}\n",
    "    vocab = {}\n",
    "    for sentence in collection:\n",
    "        for word in clean_and_split(sentence):\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except:\n",
    "                vocab[word] = 1\n",
    "    _vocab = sorted(vocab.items(), key=itemgetter(1), reverse=True)[:size]\n",
    "    id2word = [i[0] for i in _vocab]\n",
    "    word2id = {id2word[i]:i for i in range(len(id2word))}\n",
    "    return _vocab, id2word, word2id\n",
    "\n",
    "def make_set(pos, neg, vocab, shuffle=True):\n",
    "    X = [clean_and_split(i) for i in pos + neg]\n",
    "    y = [1] *len(pos) + [0] * len(neg)\n",
    "    if shuffle:\n",
    "        shuffle_arr(X)\n",
    "        shuffle_arr(y)\n",
    "    return to_bow(X, vocab), y\n",
    "\n",
    "def to_bow(X, vocab):\n",
    "    '''\n",
    "    Input:  X -> matrix of samples\n",
    "            vocab -> list of words\n",
    "    Return: Binary array indicating if the word appear in the sample\n",
    "    '''\n",
    "    \n",
    "    return np.array([[i in sample for i in vocab] for sample in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def prob(x, w):\n",
    "    return sigmoid(np.dot(x, w))\n",
    "\n",
    "def loss(x, y, w):\n",
    "    m = x.shape[0]           #2000x1\n",
    "    return -(1 / m) * np.sum(y * np.log(prob(x, w)) + (1 - y) * np.log(1 - prob(x, w)))\n",
    "\n",
    "def gradient(x, y, w):\n",
    "    m = x.shape[0]\n",
    "    return (1 / m) * np.dot(x.T, prob(x, w) - y)\n",
    "\n",
    "    \n",
    "\n",
    "def fit(x, y, w=[], alpha=0.1, loss_f=loss, num_epochs=300, batch_size=20):\n",
    "    \n",
    "    w = np.random.uniform(-0.5,0.50001, size=len(x[0]))\n",
    "    m = x.shape[0]\n",
    "    for _ in range(num_epochs):\n",
    "        print(\"Epoch: {}\".format(_))\n",
    "        for i in range(0, m, batch_size):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            b_x = x[start:end]\n",
    "            b_y = y[start:end]\n",
    "            print(\"Segment: {}-{}\".format(start, end))\n",
    "            y_pred = np.dot(b_x, w)\n",
    "            residuals = y_pred - b_y\n",
    "            g_vals = np.dot(b_x.T, residuals)\n",
    "            w -= (alpha / m) * g_vals\n",
    "            l = loss(b_x, b_y, w)\n",
    "    return w\n",
    "\n",
    "def predict(x, w):\n",
    "    return prob(x, w)\n",
    "\n",
    "def accuracy(x, y, eps=.5):\n",
    "    pred = predict(x) >= eps\n",
    "    return np.mean(pred.flatten() == y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading train and test set from files\n",
    "train_pos = read_files('./train/pos')\n",
    "train_neg = read_files('./train/neg')\n",
    "test_pos = read_files('./test/pos')\n",
    "test_neg = read_files('./test/neg')\n",
    "\n",
    "#shuffling to avoid \"Sorted Bias\" \n",
    "shuffle_arr(train_pos)\n",
    "shuffle_arr(train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training set into training and validation\n",
    "val_pos, val_neg = train_pos[:2500], train_neg[:2500]\n",
    "train_pos, train_neg = train_pos[2500:], train_neg[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, id2word, word2id = vocabulary_builder(train_pos + train_neg)\n",
    "#transforming the sets into a binary representation\n",
    "X_train, y_train = make_set(train_pos, train_neg, id2word)\n",
    "X_val, y_val = make_set(val_pos,val_neg, id2word, False)\n",
    "X_test, y_test = make_set(test_pos, test_neg, id2word, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Segment: 0-20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-d54345b446fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-4185ff42d2a7>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(x, y, w, alpha, loss_f, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mg_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresiduals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mw\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mg_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-4185ff42d2a7>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(x, y, w)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m           \u001b[1;31m#2000x1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "w = fit(X_train,y_train, num_epochs=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train, open('X_train', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51405"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((prob(X_train, w) >.5).flatten() == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0263681481703864"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed()\n",
    "w = np.random.uniform(-0.5,0.50001, size=len(X_train[0]))\n",
    "costs = []\n",
    "alpha = 0.5\n",
    "for i in range(10):\n",
    "    p = sigmoid(np.dot(X_train[i], w))\n",
    "    \n",
    "    costs.append(-y_train[i] * np.log(p) - (1 - y_train[i]) * np.log(1 - p))\n",
    "\n",
    "np.mean(costs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
