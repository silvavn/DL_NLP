{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = os.listdir('./train/pos')\n",
    "train_neg = os.listdir('./train/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(address):\n",
    "    #Read all files given an address\n",
    "    #Returns: list of strings\n",
    "    my_files = os.listdir(address)\n",
    "    return [open(\"{}/{}\".format(address,i),'r', encoding='utf-8').read() for i in my_files]\n",
    "\n",
    "def shuffle_arr(arr, seed=314):\n",
    "    #Shuffles a list\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(arr)\n",
    "\n",
    "def clean_and_split(text):\n",
    "    #Takes a string, removes white spaces, makes it lowercase and splits given space\n",
    "    #Input: string\n",
    "    #Returns: list of strings\n",
    "    return text.strip().lower().split()\n",
    "\n",
    "def vocabulary_builder(collection, size=2000):\n",
    "    #Takes a list of strings and creates a simple counter and vocabulary\n",
    "    #Input: list of strings\n",
    "    #Returns: dict of strings {word:count}\n",
    "    vocab = {}\n",
    "    for sentence in collection:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except:\n",
    "                vocab[word] = 1\n",
    "    _vocab = sorted(vocab.items(), key=itemgetter(1), reverse=True)[:size]\n",
    "    id2word = [i[0] for i in _vocab]\n",
    "    word2id = {id2word[i]:i for i in range(len(id2word))}\n",
    "    return _vocab, id2word, word2id\n",
    "\n",
    "def make_set(pos, neg, vocab, shuffle=True):\n",
    "    X = [clean_and_split(i) for i in pos + neg]\n",
    "    y = [1] *len(pos) + [0] * len(neg)\n",
    "    if shuffle:\n",
    "        shuffle_arr(X)\n",
    "        shuffle_arr(y)\n",
    "    return to_bow(X, vocab), y\n",
    "\n",
    "def to_bow(X, vocab):\n",
    "    '''\n",
    "    Input:  X -> matrix of samples\n",
    "            vocab -> list of words\n",
    "    Return: Binary array indicating if the word appear in the sample\n",
    "    '''\n",
    "    \n",
    "    return np.array([i in sentence for i in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def prob(x, w):\n",
    "    return sigmoid(np.dot(x, w))\n",
    "\n",
    "def loss(x, y, w):\n",
    "    m = x.shape[0]           #2000x1\n",
    "    return -(1 / m) * np.sum(y * np.log(prob(x, w)) + (1 - y) * np.log(1 - prob(x, w)))\n",
    "\n",
    "def gradient(x, y, w):\n",
    "    m = x.shape[0]\n",
    "    return (1 / m) * np.dot(x.T, prob(x, w) - y)\n",
    "    \n",
    "def fit(x, y, w=[], alpha=0.1, loss_f=loss, num_epochs=300, batch_size=20):\n",
    "    w = np.random.uniform(-0.5,0.50001, size=len(x[0]))\n",
    "    m = x.shape[0]\n",
    "    for _ in range(len(num_epochs)):\n",
    "        for i in range(m, batch_size):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            b_x = x[start:end]\n",
    "            b_y = y[start:end]\n",
    "            \n",
    "            y_pred = np.dot(b_x, w)\n",
    "            residuals = y_pred - b_y\n",
    "            g_vals = np.dot(b_x.T, residuals)\n",
    "            w -= (alpha / m) * g_vals\n",
    "            l = loss(b_x, b_y, w)\n",
    "    return w\n",
    "\n",
    "def predict(x, w):\n",
    "    return np.dot(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading train and test set from files\n",
    "train_pos = read_files('./train/pos')\n",
    "train_neg = read_files('./train/neg')\n",
    "test_pos = read_files('./test/pos')\n",
    "test_neg = read_files('./test/neg')\n",
    "\n",
    "#shuffling to avoid \"Sorted Bias\" \n",
    "shuffle_arr(train_pos)\n",
    "shuffle_arr(train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training set into training and validation\n",
    "val_pos, val_neg = train_pos[:2500], train_neg[:2500]\n",
    "train_pos, train_neg = train_pos[2500:], train_neg[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Being an otaku since the days of Robotech, I can still say that Gunbuster is one of my favorite animes of all time. Considering when it was made, the animation is of superior quality. There are no loops and sequences in which the art decreases in quality. Although the final episode is in black and white, it does not detract from the enjoyment of watching the film. Although it has been described as being \"sappy,\" it should be kept in mind that females do not react in the same way that males do. Since the main character is a female, it should be obvious that she does not necessarily need to resort to \"macho-man\" tactics in order to gain the respect of her peers. The seiryuu for Noriko, incidentally, also plays Akane in Ranma 1/2. Noriko is as 3-dimensional a cartoon can get; her personality captures the essence of a spirited girl who seems at first to be completely helpless but in the end succeeds through the strength of her will. The only complaint I have is that the mecha looked somewhat like teddy bears. Even the Gunbuster utilizes a rather dubious \"Homing Laser\" and \"Buster Shield\" (which is nothing more than having the machine wrap a giant velvety cloak around itself in true Dracula style) technique. I doubt that scene was meant to be funny, but it cracked me up. Yet all in all, I would rank Gunbuster in the top 20 anime of all time.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5bdfcc129da3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#transforming the sets into a binary representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-18f8e99c509c>\u001b[0m in \u001b[0;36mmake_set\u001b[1;34m(pos, neg, vocab, shuffle)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mshuffle_arr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mshuffle_arr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mto_bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-18f8e99c509c>\u001b[0m in \u001b[0;36mto_bow\u001b[1;34m(X, vocab)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mReturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBinary\u001b[0m \u001b[0marray\u001b[0m \u001b[0mindicating\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mword\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     '''\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-18f8e99c509c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mReturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBinary\u001b[0m \u001b[0marray\u001b[0m \u001b[0mindicating\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mword\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     '''\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "vocab, id2word, word2id = vocabulary_builder(train_pos + train_neg)\n",
    "#transforming the sets into a binary representation\n",
    "X_train, y_train = make_set(train_pos, train_neg, vocab)\n",
    "X_val, y_val = make_set(val_pos,val_neg, vocab, False)\n",
    "X_test, y_test = make_set(test_pos, test_neg, vocab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.uniform(-0.5, 0.50001, size=2000)\n",
    "predict(X_val, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train, open('X_train', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'line',\n",
       " 'is',\n",
       " 'funnier',\n",
       " 'in',\n",
       " 'england,',\n",
       " 'where,',\n",
       " 'away',\n",
       " 'from',\n",
       " \"vixen!'s\",\n",
       " 'native',\n",
       " 'america,',\n",
       " 'the',\n",
       " 'word',\n",
       " '\"fanny\"',\n",
       " 'has',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'new',\n",
       " 'meaning.',\n",
       " 'sadly,',\n",
       " \"it's\",\n",
       " 'the',\n",
       " 'only',\n",
       " 'laugh',\n",
       " \"you'll\",\n",
       " 'get',\n",
       " 'in',\n",
       " 'this',\n",
       " 'terrible',\n",
       " 'sex',\n",
       " 'comedy',\n",
       " 'that',\n",
       " 'is',\n",
       " 'neither',\n",
       " 'sexy',\n",
       " 'nor',\n",
       " 'funny.<br',\n",
       " '/><br',\n",
       " '/>oddly',\n",
       " 'unalluring',\n",
       " 'with',\n",
       " 'painted-on',\n",
       " 'eyebrows,',\n",
       " 'erica',\n",
       " 'gavin',\n",
       " '(acting',\n",
       " 'ability:',\n",
       " 'zero)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'nymphomaniac',\n",
       " 'who',\n",
       " 'lusts',\n",
       " 'after',\n",
       " 'her',\n",
       " 'own',\n",
       " 'brother,',\n",
       " 'but',\n",
       " 'rejects',\n",
       " 'his',\n",
       " 'black',\n",
       " 'friend',\n",
       " 'while',\n",
       " 'making',\n",
       " 'derogatory',\n",
       " 'remarks',\n",
       " 'about',\n",
       " 'watermelons.',\n",
       " 'as',\n",
       " 'if',\n",
       " 'in',\n",
       " 'revenge,',\n",
       " 'he',\n",
       " 'asks',\n",
       " 'her',\n",
       " 'if',\n",
       " 'she',\n",
       " 'would',\n",
       " 'go',\n",
       " 'with',\n",
       " 'a',\n",
       " 'shetland',\n",
       " 'pony.',\n",
       " 'reference',\n",
       " 'is',\n",
       " 'also',\n",
       " 'made',\n",
       " 'to',\n",
       " '\"making',\n",
       " 'it',\n",
       " 'with',\n",
       " 'monkeys\".',\n",
       " \"gavin's\",\n",
       " 'ability',\n",
       " 'to',\n",
       " 'shake',\n",
       " 'and',\n",
       " 'tremble',\n",
       " 'with',\n",
       " 'orgasmic',\n",
       " 'pleasure',\n",
       " 'at',\n",
       " 'the',\n",
       " 'slightest',\n",
       " 'touch',\n",
       " 'is',\n",
       " 'matched',\n",
       " 'only',\n",
       " 'in',\n",
       " \"it's\",\n",
       " 'lack',\n",
       " 'of',\n",
       " 'appeal',\n",
       " 'by',\n",
       " 'her',\n",
       " 'seduction',\n",
       " 'dance',\n",
       " '\\x96',\n",
       " 'which',\n",
       " 'involves',\n",
       " 'a',\n",
       " 'bonfire',\n",
       " 'and',\n",
       " 'a',\n",
       " 'haddock.',\n",
       " 'personally,',\n",
       " 'i',\n",
       " 'preferred',\n",
       " 'the',\n",
       " 'haddock.<br',\n",
       " '/><br',\n",
       " '/>for',\n",
       " \"'68\",\n",
       " 'this',\n",
       " 'was',\n",
       " 'pretty',\n",
       " 'tame',\n",
       " 'stuff,',\n",
       " 'and',\n",
       " 'belies',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'it',\n",
       " 'attracted',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time.',\n",
       " 'a',\n",
       " 'character',\n",
       " 'claims',\n",
       " 'to',\n",
       " 'be',\n",
       " '\"getting',\n",
       " 'stoned\",',\n",
       " 'though',\n",
       " \"it's\",\n",
       " 'only',\n",
       " 'on',\n",
       " 'bourbon,',\n",
       " 'and',\n",
       " 'for',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'original',\n",
       " '\"x\"',\n",
       " 'certificates,',\n",
       " \"there's\",\n",
       " 'no',\n",
       " 'full',\n",
       " 'frontal',\n",
       " 'nudity.',\n",
       " 'just',\n",
       " 'six',\n",
       " 'years',\n",
       " 'later',\n",
       " 'we',\n",
       " 'would',\n",
       " 'be',\n",
       " 'getting',\n",
       " 'timmy',\n",
       " 'lea',\n",
       " 'and',\n",
       " 'his',\n",
       " 'confessions,',\n",
       " 'but',\n",
       " 'here',\n",
       " 'we',\n",
       " 'have',\n",
       " 'to',\n",
       " 'make',\n",
       " 'do',\n",
       " 'with',\n",
       " 'topless',\n",
       " 'shots.',\n",
       " 'only',\n",
       " \"gavin's\",\n",
       " 'final',\n",
       " 'seduction',\n",
       " 'of',\n",
       " 'her',\n",
       " 'own',\n",
       " 'brother',\n",
       " 'really',\n",
       " 'shocks.',\n",
       " 'another',\n",
       " 'activity',\n",
       " 'for',\n",
       " 'vixen',\n",
       " 'is',\n",
       " 'where',\n",
       " 'she',\n",
       " 'helps',\n",
       " 'settle',\n",
       " 'the',\n",
       " 'sexual',\n",
       " 'problems',\n",
       " 'between',\n",
       " 'a',\n",
       " 'married',\n",
       " 'couple',\n",
       " 'by',\n",
       " 'sleeping',\n",
       " 'with',\n",
       " 'them',\n",
       " 'both.',\n",
       " 'the',\n",
       " 'two',\n",
       " 'women',\n",
       " 'clearly',\n",
       " \"aren't\",\n",
       " 'enjoying',\n",
       " 'acting',\n",
       " 'out',\n",
       " 'their',\n",
       " 'scene',\n",
       " 'together,',\n",
       " 'and',\n",
       " 'make',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'disguise',\n",
       " 'it.',\n",
       " 'after',\n",
       " 'vixen',\n",
       " 'irons',\n",
       " 'out',\n",
       " 'their',\n",
       " 'disharmony,',\n",
       " 'the',\n",
       " 'romantic',\n",
       " 'husband',\n",
       " 'concludes',\n",
       " 'of',\n",
       " 'his',\n",
       " 'wife',\n",
       " '\"i',\n",
       " 'guess',\n",
       " \"she's\",\n",
       " 'got',\n",
       " 'it',\n",
       " 'coming',\n",
       " 'to',\n",
       " 'her!\"<br',\n",
       " '/><br',\n",
       " '/>the',\n",
       " 'only',\n",
       " 'near-worthwhile',\n",
       " 'segment',\n",
       " 'involves',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'discussion',\n",
       " 'of',\n",
       " 'cuban',\n",
       " 'communism.',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'out',\n",
       " 'of',\n",
       " 'place',\n",
       " 'with',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'film,',\n",
       " 'though',\n",
       " 'is',\n",
       " 'spliced',\n",
       " 'with',\n",
       " 'shots',\n",
       " 'of',\n",
       " \"gavin's\",\n",
       " 'breasts',\n",
       " 'to',\n",
       " 'rope',\n",
       " 'it',\n",
       " 'in',\n",
       " 'to',\n",
       " 'continuity.',\n",
       " 'this',\n",
       " 'then',\n",
       " 'leads',\n",
       " 'into',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'anti-vietnam',\n",
       " 'stance,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'commendable,',\n",
       " 'though',\n",
       " 'dropped',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'such',\n",
       " 'a',\n",
       " 'frivolous',\n",
       " 'film',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'trite',\n",
       " 'and',\n",
       " 'insensitive,',\n",
       " 'not',\n",
       " 'to',\n",
       " 'say',\n",
       " 'downright',\n",
       " 'tasteless.',\n",
       " 'incidentally,',\n",
       " 'the',\n",
       " 'part',\n",
       " 'of',\n",
       " 'would-be',\n",
       " 'communist',\n",
       " 'niles',\n",
       " 'brooke',\n",
       " 'is',\n",
       " 'taken',\n",
       " 'by',\n",
       " 'harrison',\n",
       " 'page,',\n",
       " 'the',\n",
       " 'same',\n",
       " 'harrison',\n",
       " 'page',\n",
       " 'who',\n",
       " 'played',\n",
       " 'captain',\n",
       " 'trunk',\n",
       " 'in',\n",
       " 'amusing',\n",
       " 'comedy',\n",
       " 'sledge',\n",
       " 'hammer!',\n",
       " 'page',\n",
       " 'must',\n",
       " 'be',\n",
       " 'embarrassed',\n",
       " 'by',\n",
       " 'his',\n",
       " 'back',\n",
       " 'catalogue',\n",
       " '(which',\n",
       " 'also',\n",
       " 'includes',\n",
       " \"meyer's\",\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'valley',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dolls),',\n",
       " 'though',\n",
       " 'meyer',\n",
       " 'apologists',\n",
       " 'would',\n",
       " 'have',\n",
       " 'you',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'terrible',\n",
       " 'dialogue,',\n",
       " 'lousy',\n",
       " 'acting,',\n",
       " 'sloppy',\n",
       " 'direction',\n",
       " 'and',\n",
       " 'dire',\n",
       " 'editing',\n",
       " 'are',\n",
       " 'not',\n",
       " 'just',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'charm,',\n",
       " 'but',\n",
       " 'wholly',\n",
       " 'intentional.',\n",
       " 'as',\n",
       " 'a',\n",
       " 'defence,',\n",
       " 'it',\n",
       " 'fails',\n",
       " 'to',\n",
       " 'hold',\n",
       " 'water.<br',\n",
       " '/><br',\n",
       " '/>the',\n",
       " 'irritating',\n",
       " 'incidental',\n",
       " 'music',\n",
       " '\\x96',\n",
       " 'a',\n",
       " 'cross',\n",
       " 'between',\n",
       " 'the',\n",
       " 'tunes',\n",
       " 'they',\n",
       " 'play',\n",
       " 'in',\n",
       " 'cinema',\n",
       " 'restaurant',\n",
       " 'ads',\n",
       " 'and',\n",
       " 'muzak',\n",
       " 'used',\n",
       " 'by',\n",
       " 'tv',\n",
       " 'stations',\n",
       " 'when',\n",
       " 'the',\n",
       " 'transmission',\n",
       " 'breaks',\n",
       " 'down',\n",
       " '\\x96',\n",
       " 'is',\n",
       " 'omnipresent',\n",
       " 'and',\n",
       " 'intrusive;',\n",
       " 'while',\n",
       " 'even',\n",
       " 'the',\n",
       " 'silly,',\n",
       " 'amateurishly',\n",
       " 'skewed',\n",
       " 'camera',\n",
       " 'angles',\n",
       " \"can't\",\n",
       " 'generate',\n",
       " 'interest.',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'world',\n",
       " 'of',\n",
       " 'jazz',\n",
       " 'saxophones,',\n",
       " 'where',\n",
       " 'women',\n",
       " 'have',\n",
       " 'been',\n",
       " '\"asking',\n",
       " 'for',\n",
       " 'it\",',\n",
       " 'black',\n",
       " 'men',\n",
       " '\\x96',\n",
       " 'or',\n",
       " '\"shines\"',\n",
       " '\\x96',\n",
       " \"aren't\",\n",
       " 'good',\n",
       " 'enough',\n",
       " 'for',\n",
       " 'anyone,',\n",
       " 'and',\n",
       " 'rape',\n",
       " 'is',\n",
       " 'an',\n",
       " 'acceptable',\n",
       " 'form',\n",
       " 'of',\n",
       " 'revenge.',\n",
       " 'absolutely',\n",
       " 'abysmal.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
